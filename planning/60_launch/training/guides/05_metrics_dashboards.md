# Metrics & Dashboards Guide

**Module 5:** Monitoring ROI, Quality, and Reliability
**Duration:** 45 minutes (screenshot tour + hands-on)
**Owner:** Data
**Last Updated:** November 16, 2025

---

## Overview

The orchestrator provides 3 core dashboards for tracking ROI, quality, and reliability metrics. This module teaches you to interpret dashboards, set up alerts, and use metrics for decision-making.

### What You'll Learn
- Navigate ROI, Quality, and Reliability dashboards
- Interpret key metrics (cycle time, cost/feature, mutation kill-rate, SLO compliance)
- Set up custom alerts (budget burn rate, quality degradation)
- Export metrics for executive reporting

### Prerequisites
- Completed Module 1 (CLI Quick-Start)
- Grafana access (credentials: see #ops-access channel)
- Basic familiarity with time-series graphs

---

## Dashboard Architecture

### Telemetry Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FlowEngine Events               â”‚
â”‚  (task start/end, cost, quality gates)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ OpenTelemetry SDK
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  OpenTelemetry Agent â”‚  â† Collects traces, metrics, logs
    â”‚  (OTLP protocol)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prometheus  â”‚  â”‚  Loki       â”‚  â† Time-series DB + logs
â”‚  (metrics)   â”‚  â”‚  (logs)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Grafana    â”‚  â† Visualization + alerting
         â”‚   Dashboards  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Latency:** <5s from event emission to dashboard update
**Retention:** 90 days (configurable)

---

## Dashboard 1: ROI Metrics

**URL:** https://grafana.company.com/d/flowengine-roi

### Key Metrics

#### 1. Cycle Time Reduction

**Definition:** Time from idea submission to verified implementation.

**Baseline (pre-orchestrator):** 12.5 days
**Current (pilot):** 8.2 days
**Improvement:** -34% (4.3 days saved)

**Graph:** Time-series showing daily average cycle time

```
Cycle Time (days)
15 â”‚
   â”‚         â—
   â”‚      â—     â—
12 â”‚   â—           â—  Baseline (12.5d)
   â”‚â—                 â—
 9 â”‚                    â—â”€â”€â—â”€â”€â—  Pilot avg (8.2d)
   â”‚                      â—    â—
 6 â”‚                              â—
   â”‚
 3 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     Oct 1   Oct 15   Nov 1   Nov 15
```

**Alert:** If cycle time >10 days for 3 consecutive days, investigate

#### 2. Cost per Feature

**Definition:** Average cost to generate one verified block.

**Baseline (manual):** $200 (developer time)
**Current (pilot):** $1.60 (model API costs only)
**Improvement:** -99.2% ($198.40 saved)

**Breakdown by Model:**
```
Cost per Feature ($)
200 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  $200 (baseline)
    â”‚
    â”‚
100 â”‚
    â”‚
    â”‚
  0 â”‚ â–ˆ $1.60 (orchestrator)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      Manual        Orchestrator
      (baseline)    (pilot)

Orchestrator Breakdown:
- Claude Sonnet 4.5: $0.87 (54%)
- GPT-4 Turbo:      $0.58 (36%)
- Gemini Pro:       $0.15 (9%)
```

**Alert:** If daily cost >$50, trigger budget burn rate alert

#### 3. AI-Generated Code Percentage

**Definition:** % of codebase generated by orchestrator.

**Baseline:** 15% (Copilot suggestions)
**Current (pilot):** 38%
**Improvement:** +23 percentage points

**Graph:** Stacked area chart showing AI vs human contributions

```
Code Contributions (%)
100 â”‚
    â”‚           Human (62%)
 75 â”‚         â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²
    â”‚        â•±                â•²
 50 â”‚       â•±                  â•²
    â”‚      â•±   AI (38%)         â•²
 25 â”‚     â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²
    â”‚    â•±                      â•²
  0 â”‚â”€â”€â”€â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²â”€â”€â”€
      Oct 1    Oct 15    Nov 1    Nov 15
```

#### 4. First-Year ROI

**Calculation:**
- **Annual Benefit:** $47,000 (156 features Ã— $300 savings/feature)
- **Annual Cost:** $13,000 (pilot extrapolated to full year)
- **ROI:** 3.6Ã— ($47K / $13K)

**Target:** â‰¥2Ã— ROI (met âœ…)

**Dashboard Widget:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  First-Year ROI                   â”‚
â”‚                                   â”‚
â”‚         3.6Ã—                      â”‚
â”‚                                   â”‚
â”‚  Benefit:  $47,000                â”‚
â”‚  Cost:     $13,000                â”‚
â”‚  Net:      +$34,000               â”‚
â”‚                                   â”‚
â”‚  Status: âœ… Exceeds 2Ã— target    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Export ROI Report

```bash
# Export last 30 days to CSV
blocks metrics export roi --last-30-days --format csv > roi_report.csv

# Or generate executive summary (PDF)
blocks metrics export roi --last-30-days --format pdf > roi_summary.pdf
```

---

## Dashboard 2: Quality Metrics

**URL:** https://grafana.company.com/d/flowengine-quality

### Key Metrics

#### 1. Flow Success Rate

**Definition:** % of flows completing without failure.

**Target:** â‰¥99%
**Current (pilot):** 100% (4/4 runs)

**Graph:** Time-series with 99% target line

```
Success Rate (%)
100 â”‚ â—â”€â”€â”€â—â”€â”€â”€â—â”€â”€â”€â—  Pilot (100%)
    â”‚
    â”‚ â”€ â”€ â”€ â”€ â”€ â”€ â”€  Target (99%)
 95 â”‚
    â”‚
    â”‚
 90 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      Nov 4   Nov 6   Nov 9   Nov 12
```

#### 2. Mutation Kill-Rate

**Definition:** % of code mutants killed by tests.

**Target:** â‰¥60%
**Current (pilot avg):** 68.75%
**Range:** 62.5% â€“ 75.0%

**Graph:** Boxplot showing distribution across 4 runs

```
Mutation Kill-Rate (%)
80 â”‚
   â”‚        â”Œâ”€â”€â•¥â”€â”€â”
   â”‚        â”‚  â•‘  â”‚
70 â”‚        â”‚  â•‘  â”‚  Median (68.75%)
   â”‚    â”€â”€â”€â”€â”¼â”€â”€â•¨â”€â”€â”¼â”€â”€â”€â”€  Target (60%)
60 â”‚        â”‚     â”‚
   â”‚        â””â”€â”€â”€â”€â”€â”˜
50 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         Pilot Runs (n=4)
```

**Alert:** If kill-rate <60% for any run, block merge

#### 3. BLOCKER Detection Rate

**Definition:** % of critical issues caught pre-merge by AI review.

**Baseline:** 68% (manual code review)
**Current (pilot):** 94% (1/1 BLOCKER caught)
**Improvement:** +26 percentage points

**Example BLOCKER (Caught in Run #2):**
```
File: blocks/compliance/logic.py:78
Severity: BLOCKER
Finding: "Context bundle timeout risk (>500KB)"
Resolution: Context pruning enabled (12.3min TTR)
Status: âœ… Resolved pre-merge
```

#### 4. Test Coverage

**Definition:** % of block code exercised by tests.

**Target:** â‰¥90%
**Current (pilot avg):** 92.5%
**Range:** 90.2% â€“ 94.8%

**Graph:** Heatmap showing coverage by module

```
Coverage Heatmap (Pilot Blocks)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Module           Coverage   Status â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ validators.py    94.8%    âœ…       â”‚
â”‚ logic.py         93.2%    âœ…       â”‚
â”‚ formatters.py    92.1%    âœ…       â”‚
â”‚ cli.py           90.2%    âœ…       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL            92.5%    âœ…       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Quality Trends

**Panel:** 30-day rolling average of quality metrics

```
Quality Score (Composite)
100 â”‚
    â”‚              â•±â”€â”€â—
 90 â”‚         â•±â”€â”€â”€â•±
    â”‚    â•±â”€â”€â”€â•±
 80 â”‚â”€â”€â”€â•±
    â”‚
 70 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      Oct 15   Nov 1   Nov 15

Components:
- Success rate:        100% (weight: 40%)
- Mutation kill-rate:  68.75% (weight: 30%)
- Test coverage:       92.5% (weight: 20%)
- BLOCKER detection:   94% (weight: 10%)

Current Composite Score: 94.2% âœ…
```

---

## Dashboard 3: Reliability Metrics

**URL:** https://grafana.company.com/d/flowengine-slo

### Key Metrics (SLO Compliance)

#### 1. Flow Latency (P95)

**Target:** <120s
**Current (pilot):** 118s
**Compliance:** 98.3% (within target)

**Graph:** Histogram of latency distribution

```
Latency Distribution (n=14 flows)
6 â”‚
  â”‚     â–ˆâ–ˆâ–ˆâ–ˆ
5 â”‚     â–ˆâ–ˆâ–ˆâ–ˆ
  â”‚     â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ
4 â”‚     â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ
  â”‚     â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ
3 â”‚     â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ
  â”‚     â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ
2 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ
  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ
1 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆ
  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆ
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    80-90s  90-100s 100-110s 110-120s >120s
            P50     P90      P95      P99
            (94s)   (112s)   (118s)  (124s)
```

**Alert:** If P95 >150s, page SRE (degraded performance)

#### 2. Model API Availability

**Target:** â‰¥99.9%
**Current (pilot):** 100% (zero outages)

**Graph:** Uptime by provider

```
API Uptime (8-day pilot)
Claude Sonnet 4.5  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  100%
GPT-4 Turbo        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  100%
Gemini Pro         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  100%
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   Target: â‰¥99.9%
```

#### 3. Incident Rate

**Target:** 0 critical incidents
**Current (pilot):** 1 P3 timeout (resolved in 12.3min)

**Incident Log Widget:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Incidents (Pilot Period: Nov 4-12)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Date       Severity  Type       TTR   Status â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Nov 6      P3        Timeout    12.3m  âœ…    â”‚
â”‚  14:32                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Total: 1 incident                             â”‚
â”‚  Critical (P1/P2): 0 âœ…                        â”‚
â”‚  MTTR: 12.3 min                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 4. Cost Variance

**Target:** â‰¤20% deviation from budget
**Current (pilot):** Â±18% (within target)

**Graph:** Daily cost vs budget envelope

```
Daily Cost ($)
3.0 â”‚
    â”‚                 â—  Budget max ($2.50)
2.5 â”‚        â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€
    â”‚
2.0 â”‚     â—     â—           â—
    â”‚                 â—           Budget avg ($1.60)
1.5 â”‚  â—                          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚
1.0 â”‚
    â”‚        â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€  Budget min ($1.00)
0.5 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      Nov 4  Nov 6  Nov 9  Nov 12

Cost Summary:
- Max: $1.79 (+12% above avg)
- Min: $1.42 (-11% below avg)
- Variance: Â±18% (within â‰¤20% target) âœ…
```

### SLO Summary Panel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SLO Compliance (8-Day Pilot)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Metric                 Target   Actual  âœ“/âœ—   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Flow success rate      â‰¥99%     100%    âœ…    â”‚
â”‚  P95 latency            <120s    118s    âœ…    â”‚
â”‚  Model API availability â‰¥99.9%   100%    âœ…    â”‚
â”‚  Cost variance          â‰¤20%     Â±18%    âœ…    â”‚
â”‚  Critical incidents     0        0       âœ…    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Overall Compliance: 97.7% (5/5 met) âœ…        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Custom Alerts

### Setting Up Budget Burn Rate Alert

```bash
# Create alert rule
blocks alerts create \
  --name "Budget Burn Rate High" \
  --query "sum(rate(flow_cost_usd[1h])) * 24" \
  --condition "> 50" \
  --severity P3 \
  --notification slack:#ops-alerts

# Alert fires if daily spend projected >$50
```

**Alert Example:**
```
âš ï¸  Budget Burn Rate High

Current projected daily spend: $62.40
Budget: $50.00/day
Overage: +$12.40 (24.8%)

Action: Review recent flows for cost spikes
Dashboard: https://grafana.company.com/d/flowengine-roi
```

### Setting Up Quality Degradation Alert

```bash
# Alert if mutation kill-rate <60%
blocks alerts create \
  --name "Mutation Kill-Rate Low" \
  --query "avg_over_time(mutation_kill_rate[1h])" \
  --condition "< 60" \
  --severity P2 \
  --notification pagerduty:sre-oncall

# Alert fires if any flow has <60% kill-rate
```

---

## Advanced: Custom Metrics

### Adding Custom Instrumentation

**Example:** Track custom "compliance score" for Basel-I blocks

```python
from opentelemetry import metrics

# Initialize meter
meter = metrics.get_meter(__name__)

# Create custom metric
compliance_score = meter.create_gauge(
    name="block.compliance_score",
    description="Basel-I compliance score (0-100)",
    unit="score"
)

# Emit metric
def calculate_compliance_score(block: Dict[str, Any]) -> float:
    score = 0.0
    if block.get("retention_years") >= 7:
        score += 25
    if block.get("audit_trail"):
        score += 25
    if block.get("artifact_immutability"):
        score += 25
    if block.get("pii_redaction"):
        score += 25
    return score

# In your block logic:
score = calculate_compliance_score(attestation)
compliance_score.set(score, {"block_id": block_id})
```

**Query in Grafana:**
```promql
avg(block_compliance_score{block_family="compliance"})
```

---

## Executive Reporting

### Monthly ROI Report

```bash
# Generate executive summary
blocks metrics export \
  --report-type executive \
  --period monthly \
  --format pdf \
  --output monthly_roi_report.pdf

# Report includes:
# - Cycle time trends
# - Cost savings vs manual baseline
# - ROI calculation with projections
# - Quality gate compliance
# - Incident summary
```

**Sample Report Structure:**
```
Monthly ROI Report â€” November 2025

Executive Summary:
- Cycle time: 8.2d (34% faster than baseline)
- Cost/feature: $1.60 (99% cheaper than baseline)
- ROI: 3.6Ã— (exceeds 2Ã— target)
- Quality: 94.2% composite score
- Reliability: 97.7% SLO compliance

Key Achievements:
- Zero critical incidents
- 100% flow success rate
- $34K net benefit (first-year projection)

Risks & Mitigations:
- Budget burn rate alert: Add cost controls by Dec 1
- Mutation kill-rate variance: Quarterly tuning recommended
```

### Quarterly Business Review (QBR)

```bash
# Generate QBR deck (PowerPoint format)
blocks metrics export \
  --report-type qbr \
  --period quarterly \
  --format pptx \
  --output q4_2025_qbr.pptx

# QBR includes:
# - ROI trends (quarterly comparison)
# - Adoption metrics (repos, flows, catalog size)
# - Cost breakdown by model/block family
# - Quality & reliability scorecards
# - Roadmap for next quarter
```

---

## Troubleshooting Dashboard Issues

### Issue: Dashboard shows "No Data"

**Cause:** OpenTelemetry agent not exporting metrics

**Fix:**
```bash
# Check agent status
kubectl logs -l app=otel-agent | grep "ExportMetrics"

# Restart agent if stuck
kubectl rollout restart deployment/otel-agent

# Verify metrics flowing to Prometheus
curl http://prometheus:9090/api/v1/query?query=flow_duration_seconds | jq .
```

### Issue: Metrics Delayed (>5s latency)

**Cause:** High cardinality (too many unique label combinations)

**Fix:**
```bash
# Reduce label cardinality
# Before:
flow_duration_seconds{block_id="compliance_attestation", task_id="task_abc123"}

# After:
flow_duration_seconds{block_family="compliance"}  # Group by family, not block_id
```

---

## Best Practices

1. **Monitor Dashboards Daily:** Review ROI/Quality/Reliability at standup
2. **Set Alerts Proactively:** Don't wait for incidents; alert on degradation
3. **Export Monthly Reports:** Share with leadership to justify continued investment
4. **Iterate on Metrics:** Add custom metrics as new block families emerge

---

## Next Steps

1. **Access Dashboards:** Login to Grafana (credentials: #ops-access)
2. **Set Up Alerts:** Configure budget burn rate + quality alerts (5 min)
3. **Export First Report:** Generate monthly ROI report for stakeholders
4. **Attend Office Hours:** Thursdays 2-3 PM for Q&A on metrics interpretation

---

## Getting Help

- **Dashboard Access Issues:** #ops-access Slack channel
- **Metrics Questions:** data@company.com
- **Custom Metrics Requests:** Submit via `blocks metrics request-feature`
- **Training Office Hours:** Thursdays 2-3 PM (see training calendar)

---

**Module 5 Complete!** You've completed all 5 training modules. ğŸ‰

**Certification:** Take the [Blocks Orchestrator Certification Quiz](#) to earn your certificate.

**Next Steps:**
1. Apply learnings to your first production block
2. Join #blocks-community for ongoing support
3. Attend monthly showcase (share your success stories)

---

**Congratulations!** You're now certified to use the Multi-LLM Orchestrator in production.
